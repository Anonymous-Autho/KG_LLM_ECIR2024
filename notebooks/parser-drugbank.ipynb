{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8252865",
   "metadata": {},
   "source": [
    "* Originally thought to be done with BeautifulSoup, but 1) took ages to read the full xml, and 2) didn't build a hierarchical structure.\n",
    "* Also tried with: ``bigxml`` and ``from xml.etree.ElementTree import iterparse``.\n",
    "* Thought about partitioning the document in each drug, but in the end, there was no need for that.\n",
    "* ``xmltodict`` worked well, even with the full document. Generates the adequate hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ad48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import xmltodict\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26048754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re_spaces = re.compile('\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a615f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dir + 'full database.xml','r',encoding='utf8') as xml_file:\n",
    "    data_dict = xmltodict.parse(xml_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por cada una de estos dicts, tengo que agregar informaci√≥n y relaciones a los nodos\n",
    "all_drugs = {}\n",
    "for drug in tqdm(data_dict['drugbank']['drug']):\n",
    "    dd = {}\n",
    "    \n",
    "    dd['type'] = drug['@type']\n",
    "    \n",
    "    if isinstance(drug['drugbank-id'],dict):\n",
    "        dd['drugbank-id'] = drug['drugbank-id']['#text']\n",
    "    else:\n",
    "        for did in drug['drugbank-id']:\n",
    "            if isinstance(did,dict):\n",
    "                dd['drugbank-id'] = did['#text']\n",
    "            else:\n",
    "                if 'alternate_ids' not in dd:\n",
    "                    dd['alternate_ids'] = []\n",
    "                dd['alternate_ids'].append(did)\n",
    "            \n",
    "    dd['groups'] = drug['groups']['group']\n",
    "    dd['name'] = drug['name']\n",
    "    \n",
    "    if drug['description'] is not None:\n",
    "        dd['description'] = re_spaces.sub(' ',drug['description'])\n",
    "    \n",
    "    if drug['indication'] is not None:\n",
    "        dd['indication'] = re_spaces.sub(' ',drug['indication'])\n",
    "    \n",
    "    if drug['mechanism-of-action'] is not None:\n",
    "        dd['mechanism_of_action'] = re_spaces.sub(' ',drug['mechanism-of-action'])\n",
    "    \n",
    "    if drug['toxicity'] is not None:\n",
    "        dd['toxicity'] = re_spaces.sub(' ',drug['toxicity'])\n",
    "    \n",
    "    if 'products' in drug and drug['products'] is not None:\n",
    "        pp = drug['products']['product']\n",
    "        if isinstance(pp,dict):\n",
    "            pp = [pp]\n",
    "        dd['product'] = set([x['name'] for x in pp])\n",
    "\n",
    "    if 'food-interactions' in drug and drug['food-interactions'] is not None:\n",
    "        dd['food_interactions'] = drug['food-interactions']['food-interaction']\n",
    "    \n",
    "    if 'drug-interactions' in drug and drug['drug-interactions'] is not None:\n",
    "        di = drug['drug-interactions']['drug-interaction']\n",
    "        if isinstance(di,dict):\n",
    "            di = [di]\n",
    "        dd['drug_interactions'] = {x['drugbank-id'] : x['description'] for x in di}\n",
    "    \n",
    "    if 'categories' in drug and drug['categories'] is not None:\n",
    "        cc = drug['categories']['category']\n",
    "        if isinstance(cc,dict):\n",
    "            cc = [cc]\n",
    "        dd['categories'] = {x['category'] : x['mesh-id'] for x in cc}\n",
    "\n",
    "    if 'classification' in drug:\n",
    "        dd['classification'] = {}\n",
    "        dd['classification']['description'] =  drug['classification']['description']\n",
    "        dd['classification']['direct_parent'] = drug['classification']['direct-parent'] \n",
    "        dd['classification']['kingdom'] = drug['classification']['kingdom'] \n",
    "        dd['classification']['class'] = drug['classification']['class'] \n",
    "        dd['classification']['subclass'] = drug['classification']['subclass']\n",
    "        if 'synonyms' in drug['classification']:\n",
    "            dd['classification']['synonyms'] = [x['#text'] for x in drug['classification']['synonyms']['synonym'] if x['@language'] == 'english']\n",
    "\n",
    "    all_drugs[dd['drugbank-id']] = dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path_dir + 'dict_all_drugs.pickle','wb') as file:\n",
    "    pickle.dump(all_drugs,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7c607",
   "metadata": {},
   "source": [
    "Up to this point, the drugs are parsed and information has been stored.\n",
    "\n",
    "We need to check whether there is any missing drug in the KG and fix both nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drugs = pd.read_pickle(path_dir + 'dict_all_drugs.pickle')\n",
    "len(all_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check si falta alguna de las drogas\n",
    "import os\n",
    "\n",
    "graph_drugs = set()\n",
    "path_nodes = path_dir + 'pdd_nt/'\n",
    "for ff in tqdm(os.listdir(path_nodes)):\n",
    "    if '__PDD_nodes' not in ff:\n",
    "        continue\n",
    "    print(ff)\n",
    "    nodes = pd.read_pickle(path_nodes + ff)\n",
    "    for n in nodes:\n",
    "        if 'type_' in nodes[n]: # si no tiene el type_ son prescriptions, que quedaron mal !!! :face-palm:\n",
    "            if 'drug' in nodes[n]['type_']:\n",
    "                graph_drugs.add(n)\n",
    "    del nodes\n",
    "len(graph_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1701dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_drugs - set(all_drugs.keys()) # de forma directa faltan 12 drogas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dd in graph_drugs: # chequeando los otros nombres faltan 6 drogas\n",
    "    if dd in all_drugs:\n",
    "        continue\n",
    "    found = False\n",
    "    for d,data in all_drugs.items():\n",
    "        if 'alternate_ids' in data:\n",
    "            if dd in data['alternate_ids']:\n",
    "                found = True\n",
    "                print(dd,d)\n",
    "                break\n",
    "    if not found:\n",
    "        print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar los nodos y los edges\n",
    "mapping_missing_drugs = {'DB05278':'DB00030','DB11280':'DB01914','DB08914':'DB00030','DB09159':'DB09154','DB01398':'DB00936','DB00021':'DB09532','DB09396':'DB00647','DB11245':'DB03088','DB09162':'DB14520','DB11122':'DB09255','DB09323':'DB01053','DB09396':'DB00647'} \n",
    "to_remove = ['DB05813']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating nodes with the mapping drugs\n",
    "for ff in tqdm(os.listdir(path_nodes)):\n",
    "    if '__PDD_nodes' not in ff:\n",
    "        continue\n",
    "    print(ff)\n",
    "    nodes = pd.read_pickle(path_nodes + ff)\n",
    "    \n",
    "    drugs_here = set(nodes.keys()) # para evitar tener los concurrent modification exception\n",
    "    changed = False\n",
    "    for k,v in mapping_missing_drugs.items():\n",
    "        if k in drugs_here and v not in drugs_here: # para evitar tener que volver a guardar el file\n",
    "            nodes[v] = dict(nodes[k])\n",
    "            del nodes[k]\n",
    "            changed = True\n",
    "            print(nodes[v])\n",
    "    \n",
    "    for n in to_remove:\n",
    "        if n in drugs_here:\n",
    "            del nodes[n]\n",
    "            changed = True\n",
    "    \n",
    "    if changed:\n",
    "        print('Updating...')\n",
    "        with open(path_nodes + ff,'wb') as file:\n",
    "            pickle.dump(nodes,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actualizar los arcos, para que apunten a los mappings de las drogas\n",
    "# Hay casos en los cuales hay que reemplazar los dos elementos, por eso se puede romper!!!\n",
    "all_edges = pd.read_pickle(path_nodes + '__PDD_edges.pickle')\n",
    "\n",
    "ae = set(all_edges.keys())\n",
    "deleted = dict()\n",
    "\n",
    "for edge in tqdm(ae):\n",
    "    changed = False\n",
    "    new_edge = edge\n",
    "    for md,v in mapping_missing_drugs.items(): # hay arcos en los que hay que cambiar ambos elementos, por eso primero hay que chequear todos\n",
    "        if md in edge:\n",
    "            new_edge = new_edge.replace(md,v) \n",
    "            changed = True\n",
    "    if not changed:\n",
    "        continue\n",
    "        \n",
    "    edgesp = new_edge.split('__')\n",
    "    if edgesp[0] == edgesp[1]:\n",
    "        del all_edges[edge]\n",
    "        continue\n",
    "\n",
    "    if new_edge in all_edges:\n",
    "        if edge in all_edges:\n",
    "            del all_edges[edge]\n",
    "        continue\n",
    "\n",
    "    all_edges[new_edge] = dict(all_edges[edge])\n",
    "    del all_edges[edge]\n",
    "\n",
    "with open(path_nodes + '__PDD_edges.pickle','wb') as file:\n",
    "    pickle.dump(all_edges,file)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbb406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
