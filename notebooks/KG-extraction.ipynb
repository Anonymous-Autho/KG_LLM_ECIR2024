{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d49e7d",
   "metadata": {},
   "source": [
    "#### Construcción del knowledge graph a partir de pdd data\n",
    "\n",
    "* **PDD Graph: Bidging Electronic Medical Records and Biomedical Knowledge Graphs via Entity Linking**\n",
    "    * http://kmap.xjtudlc.com/pdd\n",
    "    * https://github.com/wangmengsd/pdd-graph\n",
    "    * Colección de triplas con uris.\n",
    "    * Vincula con ICD9, DrugBank e, indirectamente, con UMLS.\n",
    "    * Viejo.\n",
    "    \n",
    "* **Building a knowledge graph to enable precision medicine**\n",
    "    * https://www.nature.com/articles/s41597-023-01960-3#code-availability\n",
    "    * https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IXA7BM\n",
    "    * https://github.com/mims-harvard/PrimeKG\n",
    "    * Parece bastante completo, aunque no se si tiene la parte de UMLS que quería agregar.\n",
    "    * Pareciera que no tiene info del ICD. Raro dado que tiene información de enfermedades.\n",
    "    * Lo que definitivamente NO tiene es lo de MIMIC, pero si están los ids de las ontologías, se puede agregar sin mucho problema.\n",
    "    * Actualizado a 2023.\n",
    "    \n",
    "* **Integrating and formatting biomedical data as pre-calculated knowledge graph embeddings in the Bioteque**\n",
    "    * https://bioteque.irbbarcelona.org/downloads\n",
    "    * https://gitlabsbnb.irbbarcelona.org/bioteque/bioteque\n",
    "    * Tiene scripts.\n",
    "    * Tiene notebooks de ejemplo.\n",
    "    * El KG no está (solo los nodos), hay que reconstruirlo.\n",
    "    * Parece ser a más bajo nivel (gen y eso).\n",
    "  \n",
    "Probablemente haya que mergear ambos KG, y completar lo que pueda faltar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b877a8",
   "metadata": {},
   "source": [
    "#### Reconstruyendo: \"Building a knowledge graph to enable precision medicine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe43a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "\n",
    "df_nodes = pd.read_csv(dir_path + 'nodes.csv')\n",
    "\n",
    "id_type_to_index = {}\n",
    "\n",
    "for i in tqdm(range(0,len(df_nodes))):\n",
    "    g.add_node(df_nodes['node_index'].values[i],node_id = df_nodes['node_id'].values[i].split('_'), # cada nodo puede englobar varios id\n",
    "                                                node_type = df_nodes['node_type'].values[i],\n",
    "                                                node_name = df_nodes['node_name'].values[i],\n",
    "                                                node_source = df_nodes['node_source'].values[i],\n",
    "                                            )\n",
    "del df_nodes\n",
    "g.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c69525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges -- del edges.csv, kg.csv o kg_giant.csv\n",
    "# kg_giant tiene más relaciones, pero los nodos no están en el grafo (solo da los ids, hay ids repetidos y hay index que agrupan más de un id)\n",
    "# kg tiene los index, con lo que la búsqueda es directa\n",
    "\n",
    "df_kg = pd.read_csv(dir_path + 'kg.csv')\n",
    "\n",
    "for i in tqdm(range(0,len(df_kg))):    \n",
    "    x = df_kg['x_index'].values[i]\n",
    "    y = df_kg['y_index'].values[i]\n",
    "\n",
    "    g.add_edge(x,y,relation=df_kg['relation'].values[i], display_relation=df_kg['display_relation'].values[i]) # las otras columnas son info de los nodos\n",
    "\n",
    "g.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b66ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_features \n",
    "\n",
    "df_drugs = pd.read_csv(dir_path + 'drug_features.csv')\n",
    "df_drugs = df_drugs.fillna('')\n",
    "for i in tqdm(range(0,len(df_drugs))):\n",
    "    for j in range(1,len(df_drugs.columns)):\n",
    "        c = df_drugs.columns[j]\n",
    "        if len(df_drugs[c].values[i]) > 0: # si tiene algo, lo agrego\n",
    "            if c == 'pathway':\n",
    "                g.nodes[df_drugs['node_index'].values[i]][c] = [x.strip() for x in df_drugs[c].values[i].split(';')]\n",
    "            else:\n",
    "                g.nodes[df_drugs['node_index'].values[i]][c] = df_drugs[c].values[i]\n",
    "    \n",
    "del df_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba000ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disease_features \n",
    "# -- los ids pueden aparecer más de una vez con distinta información!!!\n",
    "# -- los ids que están agrupados aparecen con distintos nombres !!\n",
    "# -- hay que crear las relaciones separadas para cada posible id del nodo de nombre a nombre\n",
    "\n",
    "# df_disease = pd.read_csv(dir_path + 'disease_features.csv')\n",
    "# df_disease = df_disease.fillna('')\n",
    "\n",
    "for i in tqdm(range(0,len(df_disease))): # nodo : {nodo_id : {attributes}}\n",
    "    dicti = {}\n",
    "    nid = df_disease['mondo_id'].values[i]\n",
    "    nindex = df_disease['node_index'].values[i] \n",
    "    for c in df_disease.columns[3:]:\n",
    "        \n",
    "        vv = df_disease[c].values[i]\n",
    "        if len(vv) == 0:\n",
    "            continue\n",
    "        \n",
    "        if nid not in g.nodes[nindex]: # si no existe este node_id\n",
    "            g.nodes[nindex][nid] = {}\n",
    "            if c != 'group_id_bert':\n",
    "                g.nodes[nindex][nid][c] = set([vv])\n",
    "            else:\n",
    "                g.nodes[nindex][nid][c] = set(vv.split('_'))\n",
    "        else: # si ya lo tenía\n",
    "            if c in g.nodes[nindex][nid]:\n",
    "                if c != 'group_id_bert':\n",
    "                    g.nodes[nindex][nid][c].add(vv)\n",
    "                else:\n",
    "                    g.nodes[nindex][nid][c].update(vv.split('_')) \n",
    "            else:\n",
    "                if c != 'group_id_bert':\n",
    "                    g.nodes[nindex][nid][c] = set([vv])\n",
    "                else:\n",
    "                    g.nodes[nindex][nid][c] = set(vv.split('_'))\n",
    "    \n",
    "del df_disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix in case we forgot to do it in the previous step\n",
    "for n in tqdm(g.nodes(data=True)):\n",
    "    if n[1]['node_type'] == 'disease':\n",
    "        for k,v in n[1].items():\n",
    "            if not isinstance(v,dict):\n",
    "                continue\n",
    "            tr = set()\n",
    "            for kk,vv in v.items():\n",
    "                if isinstance(vv,list) or isinstance(vv,set):\n",
    "                    g.nodes[n[0]][k][kk] = set([x for x in vv if len(x) > 0])\n",
    "                if len(g.nodes[n[0]][k][kk]) == 0:\n",
    "                    tr.add(kk) \n",
    "            for kk in tr:\n",
    "                del g.nodes[n[0]][k][kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store full graph as pickle\n",
    "nx.write_gpickle(g,dir_path + 'primeKG_original.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47756273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construcción and save triplas\n",
    "# -- itera por todos los arcos -- agrega la relación entre el origen y el destino, pero por nombre\n",
    "# -- agrega origen con cada uno de los destinos (por nombre)\n",
    "# -- agrega relación is_a drug/disease, ... (nodos)\n",
    "# -- agrega relación same_group (para vincular los ids que están en el mismo grupo) (nodos)\n",
    "# -- disease, agregar symptoms\n",
    "# para las drugs se conoce su id en DrugBank, para lo diseases no se conoce nada\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "triples = deque()\n",
    "for e in tqdm(g.edges(data=True)):\n",
    "    triples.append((g.nodes[e[0]]['node_name'],e[2]['relation'],g.nodes[e[1]]['node_name']))\n",
    "\n",
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in g.nodes(data=True):\n",
    "    \n",
    "    triples.append((n[1]['node_name'],'is_a',n[1]['node_type']))\n",
    "    \n",
    "#     if n[1]['node_type'] == 'disease':\n",
    "#         for k,v in n[1].items():\n",
    "#             if not isinstance(v,dict):\n",
    "#                 continue\n",
    "#             if 'mayo_symptoms' in v:\n",
    "#                 print(k,v['mayo_symptoms'])\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6770f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('primeKG_triples.pickle','wb') as file:\n",
    "    pickle.dump(triples,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1dc16",
   "metadata": {},
   "source": [
    "#### Reconstruyendo: \"PDD Graph: Bidging Electronic Medical Records and Biomedical Knowledge Graphs via Entity Linking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from rdflib.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = './pdd_nt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_gender.nt\n",
    "# -- genera los nodos de resource\n",
    "# -- les agrega dos propiedades, type, gender y age (por ahora no crean relaciones, solo atributos)\n",
    "\n",
    "gnt = Graph()\n",
    "gnt.parse(path_dir + \"age_gender.nt\", format=\"nt\")\n",
    "\n",
    "for e in tqdm(gnt):\n",
    "    \n",
    "    node = e[0].split('/')[-1]\n",
    "    if not g.has_node(node):\n",
    "        g.add_node(node)\n",
    "    \n",
    "    att = e[1].split('/')[-1]\n",
    "    g.nodes[node][att] = e[2][0] if att != 'age' else int(e[2][0])\n",
    "    \n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI_information.nt\n",
    "# idem que el anterior, son tres propiedades float. NO todos las tienen\n",
    "\n",
    "gnt = Graph()\n",
    "gnt.parse(path_dir + \"BMI_information.nt\", format=\"nt\")\n",
    "\n",
    "for e in tqdm(gnt):\n",
    "    \n",
    "    node = e[0].split('/')[-1]\n",
    "    if not g.has_node(node):\n",
    "        g.add_node(node)\n",
    "    \n",
    "    g.nodes[node][e[1].split('/')[-1]] = float(e[2][0])\n",
    "\n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients_basic.nt\n",
    "# agrega nodos de paciente y algunas de sus propiedades\n",
    "# agrega relación entre hospital admision y patient\n",
    "\n",
    "gnt = Graph()\n",
    "gnt.parse(path_dir + \"patients_basic.nt\", format=\"nt\")\n",
    "\n",
    "for e in tqdm(gnt):\n",
    "    source = e[0].split('/')[-1]\n",
    "    rel = e[1]\n",
    "    dest = e[2]\n",
    "    if rel.endswith('#type'):\n",
    "        if not g.has_node(source):\n",
    "            g.add_node(source)\n",
    "        g.nodes[source]['type_'] = dest.split('/')[-1] # TODO!\n",
    "    elif rel.endswith('property:hospital_admission_id') or rel.endswith('property:patient_id'):\n",
    "        pass\n",
    "    else:\n",
    "        dest = dest.split('/')[-1]\n",
    "        if source == dest:\n",
    "            continue\n",
    "        if not g.has_node(source):\n",
    "            g.add_node(source,type_='vocabulary:Admission')\n",
    "            # add hospital visit\n",
    "        if not g.has_node(dest):\n",
    "            g.add_node(dest,type_='vocabulary:Patient')\n",
    "        g.add_edge(source,dest,type_='hospital_admission_id')\n",
    "#         g.add_edge(dest,source,type_='hospital_admission_id')\n",
    "\n",
    "del gnt\n",
    "# if e[1].endswith('#type'): se chequea existencia de nodo y se agrega el atributo al nodo correspondiente\n",
    "# if e[1].endswith('hospital_admission_id'): se agrega relación entre paciente --> hospital id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(g, path_dir + 'PDD_age_bmi_patients.gpickle') # si rompo a partir de acá, puedo levantar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_patients.nt\n",
    "# -- define relación entre hospital id --> drug name, hospital id --> drug id\n",
    "# -- solo considerar el drug id, el drug name lo podríamos agregar luego, no debería ser en este punto una relación, sino un atributo\n",
    "# puedo tener una lista donde acumulo nombres y siempre saco el primero ? asumiendo que siempre están en el mismo orden\n",
    "\n",
    "gnt = Graph()\n",
    "gnt.parse(path_dir + \"drug_patients.nt\", format=\"nt\")\n",
    "\n",
    "for e in tqdm(gnt):\n",
    "    if e[1].endswith('take_drug_name'): \n",
    "        continue\n",
    "    drug = e[2].split(':')[-1]\n",
    "    hc = e[0].split('/')[-1]\n",
    "    if not g.has_node(drug):\n",
    "        g.add_node(drug,type_='drug')\n",
    "    g.add_edge(hc,drug,type_='take_drug_id')\n",
    "    \n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(g, path_dir + 'PDD_age_bmi_patients_drug.gpickle') # si rompo a partir de acá, puedo levantar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddi.nt\n",
    "# -- son relaciones entre drugs\n",
    "# -- se agregan los nodos con el type: drug (los ids de nodo son lo mismo que hay que buscar en el drugbank)\n",
    "\n",
    "gnt = Graph()\n",
    "gnt.parse(path_dir + \"ddi.nt\", format=\"nt\")\n",
    "\n",
    "for e in tqdm(gnt):\n",
    "    \n",
    "    drug1 = e[0].split(':')[-1]\n",
    "    drug2 = e[2].split(':')[-1]\n",
    "    \n",
    "    if not g.has_node(drug1):\n",
    "        g.add_node(drug1,type_='drug')\n",
    "    \n",
    "    if not g.has_node(drug2):\n",
    "        g.add_node(drug2,type_='drug')\n",
    "    \n",
    "    g.add_edge(drug1,drug2,type_='interact')\n",
    "    \n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(g, path_dir + 'PDD_age_bmi_patients_drug_interact.gpickle') # si rompo a partir de acá, puedo levantar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnose_icd_information.nt\n",
    "# -- define como nodos los códigos de ICD-9\n",
    "# -- define la relación entre los diagnósticos y la hospital id --> código ICD9\n",
    "\n",
    "# gnt = Graph()\n",
    "# gnt.parse(path_dir + \"diagnose_icd_information.nt\", format=\"nt\")\n",
    "\n",
    "i = 0\n",
    "for e in tqdm(gnt):\n",
    "    \n",
    "    hc = e[0].split('/')[-1]\n",
    "    diagnose = '/'.join(e[2].split('/')[-2:])\n",
    "    \n",
    "    if not g.has_node(diagnose):\n",
    "        g.add_node(diagnose,type_='ICD_diagnose')\n",
    "        \n",
    "    g.add_edge(hc,diagnose,type_='diagnoses_icd9')\n",
    "    \n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(g, path_dir + 'PDD_age_bmi_patients_drug_interact_diagnoses.gpickle') # si rompo a partir de acá, puedo levantar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in g.edges(data=True):\n",
    "    if 'diagnoses_icd9' in e[2]['type_']:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977da19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescriptions.nt\n",
    "# -- agrega nodos de prescription\n",
    "# -- agrega relación entre hospital id --> prescription\n",
    "# -- agrega atributos al prescription\n",
    "\n",
    "# Big file (40956557 rows). Loading everything at once does not seem to be a good idea :)\n",
    "\n",
    "gnt = Graph()\n",
    "\n",
    "with open(path_dir + \"prescriptions.nt\",'r') as file:\n",
    "    \n",
    "    for line in tqdm(file):\n",
    "        \n",
    "        if 'start_date' in line or 'end_date' in line:\n",
    "            continue\n",
    "        \n",
    "        gnt.parse(data=line, format='nt')\n",
    "        \n",
    "        if len(gnt) == 5000: # process every 10000\n",
    "            \n",
    "            for e in gnt:\n",
    "                if e[1].endswith('#type'): # agregamos la prescription al graph con el vocabulary\n",
    "                    pres = e[0].split('/')[-1]\n",
    "                    if not g.has_node(pres):\n",
    "                        g.add_node(pres,type_=e[2].split('/')[-1])\n",
    "                elif e[1].endswith('has_prescription'): # agregamos el edge entre prescription y hc. hc tiene que estar, el otro se puede agregar luego\n",
    "                    hc = e[0].split('/')[-1]\n",
    "                    pres = e[2].split('/')[-1]\n",
    "                    if not g.has_node(hc): # acá puede que falte el nodo y por eso lo agrega sin tipo!!\n",
    "                        continue\n",
    "                    if not g.has_node(pres):\n",
    "                         g.add_node(pres,type_='vocabulary:Prescription')\n",
    "                            \n",
    "                    g.add_edge(hc,pres,type_='has_prescription')\n",
    "                    \n",
    "                elif e[1].endswith('start_date') or e[1].endswith('end_date'):\n",
    "                    continue\n",
    "                    \n",
    "                elif e[1].endswith('duration_days'): # add property to prescription\n",
    "                    pres = e[0].split('/')[-1]\n",
    "                    if not g.has_node(pres):\n",
    "                        g.add_node(pres,type_='vocabulary:Prescription') \n",
    "                    g.nodes[pres]['duration_days'] = e[2]\n",
    "                    \n",
    "                elif e[1].endswith('drug_type'): # add property to prescription\n",
    "                    pres = e[0].split('/')[-1]\n",
    "                    if not g.has_node(pres):\n",
    "                        g.add_node(pres,type_='vocabulary:Prescription') \n",
    "                    g.nodes[pres]['drug_type'] = e[2]\n",
    "                    \n",
    "                elif e[1].endswith('take_drugbank_id'): # add relaion from prescription to drug\n",
    "                    pres = e[0].split('/')[-1]\n",
    "                    drug = e[2].split('/')[-1]\n",
    "                    if not g.has_node(pres):\n",
    "                        g.add_node(pres,type_='vocabulary:Prescription') \n",
    "                    if not g.has_node(drug):\n",
    "                        g.add_node(drug,type_='drug') \n",
    "                    g.add_edge(pres,drug,type_='take_drugbank_id')        \n",
    "                    \n",
    "                elif e[1].endswith('dose'): # add property to prescription\n",
    "                    pres = e[0].split('/')[-1]\n",
    "                    if not g.has_node(pres):\n",
    "                        g.add_node(pres,type_='vocabulary:Prescription') \n",
    "                    g.nodes[pres]['dose'] = e[2]\n",
    "                \n",
    "            del gnt\n",
    "            gnt = Graph()\n",
    "del gnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8065924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "i = 0\n",
    "dicti_nodes = {}\n",
    "for n in tqdm(g.nodes(data=True)):\n",
    "    dicti_nodes[n[0]] = n[1]\n",
    "    i += 1\n",
    "    if i % 1000000 == 0:\n",
    "        with open(path_dir + '__PDD_nodes_'+str(i)+'.pickle','wb') as file:\n",
    "            pickle.dump(dicti_nodes,file)\n",
    "        dicti_nodes.clear()\n",
    "        gc.collect()\n",
    "        \n",
    "if len(dicti_nodes) > 0:\n",
    "    with open(path_dir + '__PDD_nodes_'+str(i)+'.pickle','wb') as file:\n",
    "        pickle.dump(dicti_nodes,file)\n",
    "    dicti_nodes.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "i = 0\n",
    "dicti_nodes = {}\n",
    "for e in tqdm(g.edges(data=True)):   \n",
    "    dicti_nodes[e[0]+'___'+e[1]] = e[2]\n",
    "    i += 1\n",
    "    if i % 500000 == 0:\n",
    "        with open(path_dir + '__PDD_edges_'+str(i)+'.pickle','wb') as file:\n",
    "            pickle.dump(dicti_nodes,file)\n",
    "        dicti_nodes.clear()\n",
    "        gc.collect()\n",
    "\n",
    "if len(dicti_nodes) > 0:\n",
    "    with open(path_dir + '__PDD_edges_'+str(i)+'.pickle','wb') as file:\n",
    "        pickle.dump(dicti_nodes,file)\n",
    "    dicti_nodes.clear()\n",
    "    gc.collect()\n",
    "# dicti_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# las keys se pueden modificar de una, esto no genera ningún inconveniente\n",
    "import os\n",
    "keys_to_modify = set()\n",
    "for ff in tqdm(os.listdir(path_dir)):\n",
    "    if 'edges' not in ff:\n",
    "        continue\n",
    "    dd = pd.read_pickle(path_dir + ff)\n",
    "    keys_to_modify.update([x for x in dd if 'drugbank:' in x])\n",
    "    \n",
    "len(keys_to_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6697cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no hay superposición, se pueden cambiar sin problema\n",
    "edges = {}\n",
    "for ff in tqdm(os.listdir(path_dir)):\n",
    "    if 'edges' not in ff:\n",
    "        continue\n",
    "    dd = pd.read_pickle(path_dir + ff)\n",
    "    edges.update(dd)\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6681318",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_keys = set(edges.keys())\n",
    "for e in tqdm(edges_keys):\n",
    "    if 'drugbank:' in e:\n",
    "        f = e.replace('drugbank:','')\n",
    "        edges[f] = dict(edges[e])\n",
    "        del edges[e]\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a098a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chequear que el viejo ya no está y que ahora está el nuevo\n",
    "for k in tqdm(keys_to_modify):\n",
    "#     print(k)\n",
    "    kk = k.replace('drugbank:','')\n",
    "#     print(k in edges, kk in edges)\n",
    "    if kk not in edges:\n",
    "        edges[f] = dict(edges[e])\n",
    "    if k in edges:\n",
    "        del edges[k]\n",
    "#     print(k in edges, kk in edges)\n",
    "#     print(edges[kk])\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011330d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(path_dir + '__PDD_edges.pickle','wb') as file:\n",
    "    pickle.dump(edges,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb33d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay 2473 drogas\n",
    "# esto está un toque más complejo... no se si ambos van a estar en el mismo archivo, ni si van a tener la misma información\n",
    "# tendría que unir los dos dicts\n",
    "# hay drugs en todos los files !! chequear que están los dos\n",
    "\n",
    "import os\n",
    "\n",
    "drug_nodes = set()\n",
    "for ff in tqdm(os.listdir(path_dir)):\n",
    "    if 'nodes' not in ff:\n",
    "        continue\n",
    "    dd = pd.read_pickle(path_dir + ff)\n",
    "    aa = [x for x in dd if x.startswith('D') or x.startswith('d')]\n",
    "    del dd\n",
    "    print(len(aa))\n",
    "    drug_nodes.update(aa)\n",
    "len(drug_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ff in tqdm(os.listdir(path_dir)):\n",
    "    if 'nodes' not in ff:\n",
    "        continue\n",
    "    dd = pd.read_pickle(path_dir + ff)\n",
    "    nodes = set(dd.keys())\n",
    "    for n in nodes:\n",
    "        if 'drug' in n:\n",
    "            nn = n.replace('drugbank:','')\n",
    "            if nn in missing_nodes:\n",
    "                dd[nn] = dict(dd[n]) # único caso en el que hay que agregarlo\n",
    "            del dd[n]\n",
    "    with open(path_dir + ff,'wb') as file:\n",
    "        pickle.dump(dd,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in drug_nodes:\n",
    "    if d.startswith('drugbank:'):\n",
    "        if d.split(':')[-1] not in drug_nodes:\n",
    "            print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_nodes = set()\n",
    "for k in tqdm(keys_to_modify):\n",
    "    ll = k.split('___')[-1].replace('drugbank:','')\n",
    "    if ll not in drug_nodes:\n",
    "        missing_nodes.add(ll)\n",
    "missing_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592cfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos los que están mal son prescriptions\n",
    "\n",
    "path_nodes = path_dir + 'pdd_nt/'\n",
    "\n",
    "for ff in tqdm(os.listdir(path_nodes)):\n",
    "    \n",
    "    if '__PDD_nodes' not in ff:\n",
    "        continue\n",
    "    print(ff)\n",
    "    nodes = pd.read_pickle(path_nodes + ff)   \n",
    "    for n,data in tqdm(nodes.items()):\n",
    "        if 'type_' not in data:\n",
    "            if not n.startswith('pres'):\n",
    "                continue\n",
    "            changed = True\n",
    "            for k in data:\n",
    "                data[k] = str(data[k])\n",
    "            data['type_'] = 'vocabulary:Prescription'\n",
    "            nodes[n] = dict(data)\n",
    "\n",
    "    if changed:\n",
    "        print('Updating...')\n",
    "        with open(path_nodes + ff,'wb') as file:\n",
    "            pickle.dump(nodes,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794334f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save del graph\n",
    "# nx.write_gpickle(g, path_dir + 'PDD_original_graph.gpickle') # si rompo a partir de acá, puedo levantar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construcción de las triplas\n",
    "# se guardan los edges del grafo\n",
    "# se guardan algunos de los atributos de los nodos del grafo\n",
    "# no hace falta que tengan _ los nombres, pueden ser más de una palabra\n",
    "# hay atributos para hospital id y prescription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in g.nodes(data=True):\n",
    "    print(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a331ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD9CM.ttl\n",
    "# -- tiene 22533 diagnósticos\n",
    "# -- Arrancar por levantar el xml/ontology\n",
    "# si la class es de nuestro interés, le sacamos los valores\n",
    "# agregamos a las clases de interés las de subClass\n",
    "# al final, si nos quedan cosas por procesar, hacemos las queries a la web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.error, urllib.parse\n",
    "import json\n",
    "import os\n",
    "\n",
    "REST_URL = \"http://data.bioontology.org\"\n",
    "API_KEY = \"160b4fe8-01d2-4b79-8c76-e930336fec68\"\n",
    "\n",
    "def get_json(url):\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('Authorization', 'apikey token=' + API_KEY)]\n",
    "    return json.loads(opener.open(url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = set()\n",
    "diagnosis = {}\n",
    "\n",
    "for n in g.nodes(data=True):\n",
    "    if n[1]['type'] == 'ICD_diagnose' and not n[0] in diagnosis:\n",
    "        missing.add(n[0])\n",
    "        \n",
    "while len(missing) != 0:\n",
    "    icd = missing.pop() # saca elemento random\n",
    "    # search for item\n",
    "    json = get_json(REST_URL + \"/search?q=\" + term + \"&include=properties\")[\"collection\"]\n",
    "    # obtenemos las properties\n",
    "    diagnosis[icd] = {}\n",
    "    if True: # if es subclass de alguno, agregamos esa clase a la búsqueda \n",
    "        missing.add(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugBank -- es un XML\n",
    "# -- Supuestamente pude bajar toda la base de datos\n",
    "# -- No se en qué formato estará la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMLS para buscar los CUI\n",
    "# -- Está el thesaurus completo para bajar (3.9GB)\n",
    "# -- No se formato\n",
    "\n",
    "umls_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://uts-ws.nlm.nih.gov/rest/content/current/CUI/C0042904/atoms?apiKey=a6f141b2-6c07-4d21-868e-6d316346dfbd\n",
    "# -- De acá buscamos los atoms que tengan language == 'ENG'\n",
    "# -- De esos, buscamos el sourceConcept y buscamos sobre esa url\n",
    "# -- Esa url va a tener otra lista más de urls a procesar\n",
    "# -- Sigo sin entender cuáles son las relaciones importantes para sacar de acá y cómo llegar a ellas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
