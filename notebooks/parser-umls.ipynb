{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d2d5b0",
   "metadata": {},
   "source": [
    "* Es para obtener más información de relaciones entre los conceptos\n",
    "    * ``https://uts-ws.nlm.nih.gov/rest/content/current/CUI/C0042904/atoms?apiKey=a6f141b2-6c07-4d21-868e-6d316346dfbd``\n",
    "* Retorna jsons con MUCHOS links y vueltas.\n",
    "* Se pueden encontrar relaciones indirectas.\n",
    "* Se entra por los CUI, con lo que hay que obener los CUI de los ICD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = './'\n",
    "umls_api_key = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "icds = pd.read_pickle(path_dir + 'icd9_umls.pickle')\n",
    "url_atoms = 'https://uts-ws.nlm.nih.gov/rest/content/current/CUI/__ID__/atoms'\n",
    "\n",
    "all_urls = set()\n",
    "for k,v in icds.items():\n",
    "    if 'cui' not in v:\n",
    "        continue\n",
    "    all_urls.add(url_atoms.replace('__ID__',v['cui']))\n",
    "\n",
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb300579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.error, urllib.parse\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# def get_json(url): \n",
    "#     opener = urllib.request.build_opener()\n",
    "#     return json.loads(opener.open(url + '&apiKey='+umls_api_key if '?' in url else url + '?apiKey='+umls_api_key).read())\n",
    "\n",
    "\n",
    "def get_json(url):\n",
    "    response = None\n",
    "    timeout = True\n",
    "    retries = 5\n",
    "    while retries > 0 and timeout:\n",
    "        retries -= 1\n",
    "        try:\n",
    "            response = requests.get(url + '&apiKey='+umls_api_key if '?' in url else url + '?apiKey='+umls_api_key, timeout=10)\n",
    "            timeout = False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print('Timeout...')\n",
    "            timeout = True\n",
    "            time.sleep(3)\n",
    "    if response is None:\n",
    "        return response\n",
    "    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hierarchy(results_,desc=False):\n",
    "    rr = []\n",
    "    urls = set()\n",
    "    for aa in results_['result']:\n",
    "\n",
    "        if aa['rootSource'] not in vocabulary_sources:\n",
    "            continue\n",
    "    \n",
    "        rr.append(aa['ui'])\n",
    "        urls.add(aa['atoms'])\n",
    "\n",
    "    if desc:\n",
    "        rr.reverse()\n",
    "        \n",
    "    return rr,urls\n",
    "\n",
    "def process_relations(rels):\n",
    "\n",
    "    in_ = defaultdict(set)\n",
    "    out_ = defaultdict(set)\n",
    "\n",
    "    urls = set()\n",
    "\n",
    "    for rr in rels:\n",
    "        if rr['rootSource'] not in vocabulary_sources:\n",
    "            continue\n",
    "\n",
    "        if len(rr['additionalRelationLabel']) == 0:\n",
    "            continue\n",
    "\n",
    "        if cui_save['ui'] in rr['relatedId']:\n",
    "            in_[rr['additionalRelationLabel']].add(rr['relatedFromId'].split('/')[-1])\n",
    "            urls.add(rr['relatedFromId'])\n",
    "        elif cui_save['ui'] in rr['relatedFromId']:\n",
    "            out_[rr['additionalRelationLabel']].add(rr['relatedId'].split('/')[-1])\n",
    "            urls.add(rr['relatedId'])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return in_,out_,urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd643f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "vocabulary_sources = set(['ICD9CM'])\n",
    "\n",
    "if os.path.exists(path_dir + 'uts_entities.pickle'):\n",
    "    aa = pd.read_pickle(path_dir + 'uts_entities.pickle')\n",
    "    all_cuis = aa[0]\n",
    "    all_urls = aa[1]\n",
    "    processed_urls = aa[2]\n",
    "else:\n",
    "    all_cuis = defaultdict(dict)\n",
    "    processed_urls = set()\n",
    "    all_urls = set()\n",
    "    \n",
    "print(len(all_urls),len(processed_urls),len(all_cuis))\n",
    "while len(all_urls) != 0:\n",
    "    \n",
    "    uu = all_urls.pop()\n",
    "    try:\n",
    "        cui_data = get_json(uu)\n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "    \n",
    "    if cui_data is None:\n",
    "        all_urls.add(uu)\n",
    "        print('Error in url...')\n",
    "        continue\n",
    "        \n",
    "    print(len(all_urls),'---',uu)\n",
    "    processed_urls.add(uu)\n",
    "    cui_data = cui_data['result']\n",
    "    \n",
    "    if isinstance(cui_data,dict): # en los casos que retorna uno solo\n",
    "        cui_data = [cui_data]\n",
    "    \n",
    "    for x in cui_data:\n",
    "        if x['language'] != 'ENG':\n",
    "            continue\n",
    "        if x['rootSource'] not in vocabulary_sources:\n",
    "            continue\n",
    "\n",
    "        cui_save = {}\n",
    "        cui_save['ui'] = x['ui']\n",
    "        cui_save['obsolete'] = False if x['obsolete'] == 'false' else True\n",
    "        cui_save['rootSource'] = x['rootSource']\n",
    "\n",
    "        if x['sourceConcept'] != 'NONE':\n",
    "            cui_save['sourceConcept'] = x['sourceConcept']\n",
    "\n",
    "        cui_save['code'] = x['code']\n",
    "\n",
    "        try:\n",
    "            x_code = get_json(cui_save['code'])['result'] # try exceptS\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        cui_save['id'] = x_code['ui']\n",
    "\n",
    "        if x_code['ancestors'] != 'NONE':\n",
    "            try:\n",
    "                jj = get_json(x_code['ancestors'])\n",
    "                if jj is not None:\n",
    "                    if 'result' in jj:\n",
    "                        ancestors_ = process_hierarchy(jj,False)\n",
    "                        cui_save['ancestors'] = ancestors_[0]\n",
    "                        all_urls.update(ancestors_[1] - processed_urls)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "            \n",
    "        if x_code['descendants'] != 'NONE':\n",
    "            try:\n",
    "                jj = get_json(x_code['descendants'])\n",
    "                if jj is not None:\n",
    "                    if 'result' in jj:\n",
    "                        descendants_ = process_hierarchy(jj,False)\n",
    "                        cui_save['descendants'] = descendants_[0]\n",
    "                        all_urls.update(descendants_[1] - processed_urls)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        if x_code['relations'] != 'NONE':\n",
    "            try:\n",
    "                jj = get_json(x_code['relations'])\n",
    "                if jj is not None:\n",
    "                    if 'result' in jj:\n",
    "                        rels = process_relations(jj['result'])\n",
    "                        cui_save['relations_in'] = rels[0]\n",
    "                        cui_save['relations_out'] = rels[1] # { rel_type : {ids} } \n",
    "                        all_urls.update(rels[2] - processed_urls)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        if x_code['attributes'] != 'NONE':\n",
    "            cui_save['attributes'] = {}\n",
    "            try:\n",
    "                att = get_json(x_code['attributes'])\n",
    "                if att is not None:\n",
    "                    for a in att['result']:\n",
    "                        cui_save['attributes'][a['name']] = a['value']\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "                \n",
    "        all_cuis[cui_save['ui']][cui_save['id']] = cui_save\n",
    "        \n",
    "        if len(all_cuis) % 20 == 0:\n",
    "            print('Saving....')\n",
    "            with open(path_dir + 'uts_entities.pickle','wb') as file:\n",
    "                pickle.dump([all_cuis,all_urls,processed_urls],file) # de esta forma no tengo que controlar nada, dado que ya levanta las urls que faltan\n",
    "                # guardo las procesadas just in case haya muchas repetidas\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aad7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlar que todas las urls que supuestamente están procesadas, estén bajadas, si no lo están, hacer de nuevo la descarga\n",
    "\n",
    "missing = set()\n",
    "for purl in tqdm(processed_urls):\n",
    "    xx = purl.split('/')[-2]\n",
    "    if xx not in elements and xx not in elements.values():\n",
    "        missing.add(purl)\n",
    "len(missing)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay 57k urls que no fueron analizadas... o que se perdieron o que les pasó algo...\n",
    "# es bastante más que la cantidad de cosas bajadas\n",
    "# ver de poner de nuevo a bajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ffe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_urls - missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f84290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "elements = {}\n",
    "for k,v in tqdm(all_cuis.items()):\n",
    "    for kk,vv in v.items():\n",
    "        if 'id' not in vv:\n",
    "            print('------',vv)\n",
    "            continue\n",
    "        if 'ui' in vv:\n",
    "            elements[vv['id']] = vv['ui']\n",
    "        else:\n",
    "            elements[vv['id']] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9beb9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
