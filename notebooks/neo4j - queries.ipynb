{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f98f40",
   "metadata": {},
   "source": [
    "Different alternatives for building paths:\n",
    "* https://neo4j.com/labs/apoc/4.1/graph-querying/expand-spanning-tree/\n",
    "````\n",
    "graph.query(\"\"\"MATCH (p:Drug {id: \"DB00295\"})\n",
    "CALL apoc.path.spanningTree(p, {\n",
    "        minLevel: 1,\n",
    "        maxLevel: 1\n",
    "    })\n",
    "    YIELD path\n",
    "    RETURN path;\n",
    "    \"\"\")\n",
    "````\n",
    "* Query with relations and distances.\n",
    "\n",
    "````\n",
    "graph.query(\"\"\"MATCH (p:Admission {id: \"130248\"})\n",
    "-[*1..1]- (c) \n",
    "RETURN c;\n",
    "    \"\"\")\n",
    "````\n",
    "* Query with expand.\n",
    "````\n",
    "graph.query(\"\"\"\n",
    "match (c:ICD {id :'ICD9CM/427.31'})\n",
    "call apoc.path.expand(c,'*','*',0,3) yield path as pp\n",
    "return pp;\n",
    "\"\"\")\n",
    "````\n",
    "* Subgraph.\n",
    "````\n",
    "call apoc.path.subgraphNodes(startNode <id>Node/list, {maxLevel, relationshipFilter, labelFilter, bfs:true, filterStartNode:true, limit, optional:false, endNodes, terminatorNodes, sequence, beginSequenceAtStart:true}) yield node\n",
    "````\n",
    "\n",
    "Of course that retrieving neighbours is easy, but expanding the subgraph when nodes have over 10k relations is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a519db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a71383",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "NEO4J_URI= \"bolt://localhost:7687\"\n",
    "NEO4J_USERNAME= \"neo4j\" \n",
    "NEO4J_PASSWORD= \"\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7487678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cypher_queries = [] # TODO: Ver qué me conviene retornar !!\n",
    "\n",
    "search_cypher_queries.append(\"\"\"WITH $embedding AS e\n",
    "                                CALL db.index.vector.queryNodes('acts_as_index', $k, e) yield node, score\n",
    "                                RETURN node AS result\n",
    "                                ORDER BY score DESC\n",
    "                            \"\"\")\n",
    "\n",
    "search_cypher_queries.append(\"\"\"WITH $embedding AS e\n",
    "                                CALL db.index.vector.queryNodes('is_known_as_index', $k, e) yield node, score\n",
    "                                RETURN node AS result\n",
    "                                ORDER BY score DESC\n",
    "                            \"\"\")\n",
    "\n",
    "search_cypher_queries.append(\"\"\"WITH $embedding AS e\n",
    "                                CALL db.index.vector.queryNodes('is_indicated_for_index', $k, e) yield node, score\n",
    "                                RETURN node AS result\n",
    "                                ORDER BY score DESC\n",
    "                            \"\"\")\n",
    "\n",
    "search_cypher_queries.append(\"\"\"WITH $embedding AS e\n",
    "                                CALL db.index.vector.queryNodes('can_be_described_as_index', $k, e) yield node, score\n",
    "                                RETURN node AS result\n",
    "                                ORDER BY score DESC\n",
    "                            \"\"\")\n",
    "\n",
    "search_cypher_queries.append(\"\"\"WITH $embedding AS e\n",
    "                                CALL db.index.vector.queryNodes('is_known_as_icd_index', $k, e) yield node, score\n",
    "                                RETURN node AS result\n",
    "                                ORDER BY score DESC\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_name = '_df_base_queries_human_adhoc.pickle'\n",
    "df_queries = pd.read_pickle(path_dir + query_name)\n",
    "\n",
    "df_queries = df_queries[[x for x in df_queries.columns if x in set(['number','topics','description','query_summary'])]]\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80badea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.base import Chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering.stuff_prompt import CHAT_PROMPT\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "from pydantic import Field\n",
    "\n",
    "class Neo4jVectorChain(Chain):\n",
    "    \"\"\"Chain for question-answering against a neo4j vector index.\"\"\"\n",
    "\n",
    "    graph: Neo4jGraph = Field(exclude=True)\n",
    "    input_key: str = \"prompt\"  #: :meta private:\n",
    "    input_medical_key: str = 'medical_note' #: :meta private:\n",
    "    output_key: str = \"result\"  #: :meta private:\n",
    "    embeddings: SentenceTransformer = model\n",
    "    qa_chain: LLMChain = LLMChain(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0), prompt=CHAT_PROMPT)\n",
    "    indexes = search_cypher_queries\n",
    "    cache_context = {}\n",
    "    cache_context[True] = {}\n",
    "    cache_context[False] = {}\n",
    "\n",
    "    cache_nodes = {}\n",
    "    \n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Return the input keys.\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return [self.input_key, self.input_medical_key]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Return the output keys.\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        _output_keys = [self.output_key]\n",
    "        return _output_keys\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str], run_manager, k=3) -> Dict[str, Any]:\n",
    "        \"\"\"Embed a question and do vector search.\"\"\"\n",
    "        prompt = inputs[self.input_key] # desacopla la instrucción de lo que se embede para buscar en el grafo\n",
    "        medical_note = inputs[self.input_medical_key]\n",
    "        embedding = self.embeddings.encode(medical_note)\n",
    "        expand_path = inputs.get('expand_path',False)\n",
    "        \n",
    "#         if medical_note not in self.cache_context[expand_path]:\n",
    "#             print('Not in cache')        \n",
    "        retrieved_nodes = []\n",
    "        for index_ in self.indexes:\n",
    "            pp = self.graph.query(index_, {'embedding': embedding, 'k': k})\n",
    "#             print(pp)\n",
    "            retrieved_nodes.extend([x['result'] for x in pp])\n",
    "\n",
    "        add_nodes = []\n",
    "        if expand_path: # we add all node neighbours\n",
    "            print('Expanding set of retrieved nodes...')\n",
    "            rr_ = set([x['id'] for x in retrieved_nodes])\n",
    "            for x in tqdm(rr_):\n",
    "\n",
    "                if x in self.cache_nodes: # this allows more freedom in how then nodes are used\n",
    "                    print('In cache')\n",
    "                    rr = self.cache_nodes[x]\n",
    "                else:\n",
    "                    print('Not in cache')\n",
    "                    rr = graph.query(\"\"\"\n",
    "                        UNWIND $data AS x\n",
    "                        MATCH (p {id: x[\"id\"]})\n",
    "                              -[*1..1]- (c) \n",
    "                              RETURN c;\n",
    "                              \"\"\",{'data':[{'id':x}]})\n",
    "                    self.cache_nodes[x] = rr\n",
    "\n",
    "                add_nodes.extend([y['c'] for y in rr])\n",
    "\n",
    "        retrieved = set()\n",
    "        context = set()\n",
    "\n",
    "        for x in retrieved_nodes:\n",
    "            if x['id'] in retrieved:\n",
    "                continue\n",
    "            retrieved.add(x['id'])\n",
    "            if x['id'][0] == 'D': # drug\n",
    "#                 if 'is_known_as' in x: context.add(x['is_known_as'])\n",
    "#                 if 'acts_as' in x: context.append(x['acts_as'])\n",
    "                if 'is_indicated_for' in x: context.add(x['is_indicated_for'])\n",
    "#                 if 'can_be_described_as' in x: context.add(x['can_be_described_as'])\n",
    "            elif x['id'][0] == 'I': # icd\n",
    "                context.add(x['is_known_as'])\n",
    "\n",
    "        for x in add_nodes: # for the additional nodes, we only add the name of diagnoses\n",
    "            if x['id'][0] == 'I': # icd\n",
    "                context.add(x['is_known_as'])\n",
    "                    \n",
    "        result = self.qa_chain(\n",
    "            {\"question\": prompt + medical_note + 'Context: ' + ' '.join(context), \"context\": ' '.join(context)},\n",
    "        )\n",
    "        final_result = result[self.qa_chain.output_key]\n",
    "        return {self.output_key: final_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Neo4jVectorChain(graph=graph, embeddings=model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531947c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expand_path = True\n",
    "\n",
    "prompt = \"\"\"You are a helpful medical assistant who needs to retrieve relevant medical documents for your patient. \n",
    "Extract the most relevant keywords from the clinical note using the provided context. \n",
    "Response format: Do not repeat keywords. Keywords should be returned in a comma-separated list that will be used for search.\n",
    "Do not explain.\n",
    "Clinical note: \"\"\"\n",
    "\n",
    "# result = []\n",
    "for i in tqdm(range(12,len(df_queries))):\n",
    "    kk = chain({'medical_note':df_queries['description'].values[i],'prompt':prompt,'expand_path':expand_path})\n",
    "    print(kk)\n",
    "    result.append(kk)\n",
    "    time.sleep(10)\n",
    "    \n",
    "df_queries['query_KG_extract'] = result\n",
    "df_queries.to_pickle(path_dir + f'df_all_queries_KG_{str(expand_path)}.pickle')\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a helpful medical assistant that needs to retrieve relevant medical documents for your patient. \n",
    "Using the provided context, summarize the clinical note by extracting its most relevant keywords.\n",
    "Response format: Do not repeat keywords. Keywords should be returned in a comma-separated list that will be used for search.\n",
    "Do not explain.\n",
    "Clinical note: \"\"\"\n",
    "\n",
    "result = []\n",
    "for i in tqdm(range(0,len(df_queries))):\n",
    "    kk = chain({'medical_note':df_queries['description'].values[i],'prompt':prompt})\n",
    "    print(kk)\n",
    "    result.append(kk)\n",
    "    time.sleep(20)\n",
    "    \n",
    "df_queries['query_KG_summary'] = result\n",
    "df_queries.to_pickle(path_dir + f'df_all_queries_KG_{str(expand_path)}.pickle')\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfb00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a helpful medical assistant that needs to retrieve relevant medical documents for your patient. \n",
    "Using the provided context, expand the clinical note with keywords referring to medical concepts, symptoms, diseases, synonyms or other information relevant. Keywords will be used to retrieve medical documents. \n",
    "Response format: Do not repeat keywords. Only keywords should be returned in a comma-separated list.\n",
    "Clinical note: \"\"\"\n",
    "\n",
    "# result = []\n",
    "for i in tqdm(range(0,len(df_queries))):\n",
    "    kk = chain({'medical_note':df_queries['description'].values[i],'prompt':prompt})\n",
    "    print(kk)\n",
    "    result.append(kk)\n",
    "    time.sleep(20)\n",
    "    \n",
    "df_queries['query_KG_extend'] = result\n",
    "df_queries.to_pickle(path_dir + f'df_all_queries_KG_{str(expand_path)}.pickle')\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "prompt = \"\"\"You are a helpful medical assistant that needs to create queries for retrieving relevant medical documents for your patient. \n",
    "1. Using the provided context, extract the most relevant keywords from the clinical note that fully describe its content.\n",
    "Response format: Do not repeate keywords. Only keywords should be returned in a comma-separated list.\n",
    "2. Use the provided context and only the provided context, expand the extracted list of keywords with at most 20 additional relevant keywords. \n",
    "Response format: Do not repeat keywords. Only keywords should be returned in a comma-separated list.\n",
    "Clinical note: \"\"\"\n",
    "\n",
    "result = []\n",
    "for i in tqdm(range(0,len(df_queries))):\n",
    "    kk = chain({'medical_note':df_queries['description'].values[i],'prompt':prompt})\n",
    "    print(kk)\n",
    "    result.append(kk)\n",
    "    time.sleep(20)\n",
    "#     break\n",
    "\n",
    "df_queries['query_KG_combine'] = result\n",
    "df_queries.to_pickle(path_dir + f'df_all_queries_KG_{str(expand_path)}.pickle')\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries = df_queries.rename(columns={'description':'query_description'})\n",
    "df_queries['query_KG_extract'] = [x['result'] for x in df_queries['query_KG_extract']]\n",
    "df_queries['query_KG_summary'] = [x['result'] for x in df_queries['query_KG_summary']]\n",
    "df_queries['query_KG_extend'] = [x['result'] for x in df_queries['query_KG_extend']]\n",
    "\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ex = []\n",
    "ex_ep = []\n",
    "ex_un = []\n",
    "\n",
    "for x in df_queries['query_KG_combine']:\n",
    "    zz = [y.replace('\\n',' ') for y in x['result'].split('\\n') if len(y) > 0]\n",
    "    for i in range(0,len(zz)):\n",
    "        \n",
    "        if len(zz[i]) != 0:\n",
    "            if zz[i][0].isdigit():\n",
    "                zz[i] = zz[i][3:]\n",
    "\n",
    "            if zz[i].startswith('Keywords') or zz[i].startswith('Expanded'):\n",
    "                zz[i] = ' '.join(zz[i].split(':')[1:]).strip()\n",
    "            \n",
    "            if len(zz[i]) != 0:\n",
    "                # podría ser que empiecen con keywords o \"expanded keywords\"\n",
    "                if zz[i][0] == '[' and zz[i][-1] == ']':\n",
    "                    zz[i] = zz[i].replace('[','').replace(']','')\n",
    "\n",
    "                if zz[i].startswith('-'):\n",
    "                    zz[i] = zz[i].replace('- ',',')\n",
    "        \n",
    "    ex_ex.append(zz[0])\n",
    "    ex_ep.append(zz[1])\n",
    "    ex_un.append(', '.join(list(set(zz[0].split(',') + zz[1].split(','))))[1:].strip())\n",
    "    \n",
    "df_queries['query_KG_combine_extract'] = ex_ex\n",
    "df_queries['query_KG_combine_expand'] = ex_ep\n",
    "df_queries['query_KG_combine_union'] = ex_un\n",
    "\n",
    "df_queries = df_queries.drop(columns=['query_KG_combine'])\n",
    "\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.to_csv(path_dir + 'df_all_queries_adhoc__KG.csv')\n",
    "df_queries.to_pickle(path_dir + 'df_all_queries_adhoc__KG.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
